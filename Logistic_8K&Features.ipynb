{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_8K&Features.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phfeFGB-jQFH"
      },
      "source": [
        "## Logistic Regression - 8K Forms & Numerical Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNF2Q7L5jId7",
        "outputId": "8d533d53-0299-48f5-b1c4-d5f1a4241f54"
      },
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import sklearn.model_selection\n",
        "import sklearn.preprocessing as preproc\n",
        "from sklearn.feature_extraction import text\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuGFo3vqjuEc",
        "outputId": "4cfa76c8-2df7-4172-907b-072f201a034f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th5UFQNwj_D6"
      },
      "source": [
        "df = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/with_all_ft_clean.pkl\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAOUx1_85eXx"
      },
      "source": [
        "def label1(row):\n",
        "    if row[\"pct_change1\"] > row[\"mkt_excess1\"]:\n",
        "        return \"pos\"\n",
        "    else:\n",
        "        return \"neg\"\n",
        "\n",
        "def label2(row):\n",
        "    if row[\"pct_change2\"] > row[\"mkt_excess2\"]:\n",
        "        return \"pos\"\n",
        "    else:\n",
        "        return \"neg\"\n",
        "\n",
        "def label3(row):\n",
        "    if row[\"pct_change2\"] > row[\"mkt_excess2\"] + 0.005:\n",
        "        return \"positive\"\n",
        "    elif row[\"pct_change2\"] < row[\"mkt_excess2\"] - 0.005:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxbvLasbkT1-"
      },
      "source": [
        "df[\"label1\"] = df.apply(label1, axis = 1)\n",
        "df[\"label2\"] = df.apply(label2, axis = 1)\n",
        "df[\"label3\"] = df.apply(label3, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgsxsQcxkaE4"
      },
      "source": [
        "# get column names of categorical features\n",
        "item_list = [i for i in df.columns if not i.find(\"item\")]\n",
        "ind_list = [i for i in df.columns if not i.find(\"ind\")]\n",
        "shrcd_list = [i for i in df.columns if not i.find(\"SHRCD\")]\n",
        "exc_list = [i for i in df.columns if not i.find(\"EXCHCD\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_gGYOfokhvx"
      },
      "source": [
        "# combine all feature column names\n",
        "cols = ['VIX', \"Mkt_Cap\"]\n",
        "cols.extend(item_list)\n",
        "cols.extend(ind_list)\n",
        "cols.extend(shrcd_list)\n",
        "cols.extend(exc_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg8_Nu6R4qSG"
      },
      "source": [
        "#### To get 1-day binary, 2-day binary, and multinomial labels, column name can be changed as \"label1\", \"label2\", \"label3\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTpZgNpqklJf"
      },
      "source": [
        "# Separate into features, documents and label\n",
        "cols = ['VIX', \"Mkt_Cap\"]\n",
        "cols.extend(item_list)\n",
        "cols.extend(ind_list)\n",
        "cols.extend(shrcd_list)\n",
        "cols.extend(exc_list)\n",
        "\n",
        "X = df[cols]\n",
        "\n",
        "docs = df['texts']\n",
        "\n",
        "#change the label for different outcomes\n",
        "y = df['label2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3O8_m81lOa1"
      },
      "source": [
        "#### Process texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5UHGtORk-Id"
      },
      "source": [
        "contractions = { \n",
        "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
        "\"aren't\": \"are not / am not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had / he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he shall / he will\",\n",
        "\"he'll've\": \"he shall have / he will have\",\n",
        "\"he's\": \"he has / he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how has / how is / how does\",\n",
        "\"I'd\": \"I had / I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I shall / I will\",\n",
        "\"I'll've\": \"I shall have / I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had / it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it shall / it will\",\n",
        "\"it'll've\": \"it shall have / it will have\",\n",
        "\"it's\": \"it has / it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she had / she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she shall / she will\",\n",
        "\"she'll've\": \"she shall have / she will have\",\n",
        "\"she's\": \"she has / she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as / so is\",\n",
        "\"that'd\": \"that would / that had\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that has / that is\",\n",
        "\"there'd\": \"there had / there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there has / there is\",\n",
        "\"they'd\": \"they had / they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they shall / they will\",\n",
        "\"they'll've\": \"they shall have / they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had / we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what shall / what will\",\n",
        "\"what'll've\": \"what shall have / what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what has / what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when has / when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where has / where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who shall / who will\",\n",
        "\"who'll've\": \"who shall have / who will have\",\n",
        "\"who's\": \"who has / who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why has / why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had / you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you shall / you will\",\n",
        "\"you'll've\": \"you shall have / you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDBVnUDMlMMo"
      },
      "source": [
        "def clean_text(text, remove_stopwords = True):\n",
        "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
        "    \n",
        "    # Convert words to lower case\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Replace contractions with their longer forms \n",
        "    if True:\n",
        "        text = text.split()\n",
        "        new_text = []\n",
        "        for word in text:\n",
        "            if word in contractions:\n",
        "                new_text.append(contractions[word])\n",
        "            else:\n",
        "                new_text.append(word)\n",
        "        text = \" \".join(new_text)\n",
        "    \n",
        "    # Format words and remove unwanted characters\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\<a href', ' ', text)\n",
        "    text = re.sub(r'&amp;', '', text) \n",
        "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
        "    text = re.sub(r'<br />', ' ', text)\n",
        "    text = re.sub(r'\\'', ' ', text)\n",
        "    \n",
        "    # remove stop words\n",
        "    if remove_stopwords:\n",
        "        text = text.split()\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        text = [w for w in text if not w in stops]\n",
        "        text = \" \".join(text)\n",
        "\n",
        "    # Tokenize each word\n",
        "    text =  nltk.WordPunctTokenizer().tokenize(text)\n",
        "        \n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bAJ7dbQlWya",
        "outputId": "32fd2751-356b-424e-b4e9-add6a0876d04"
      },
      "source": [
        "# apply clean function to documents\n",
        "docs = df.texts.apply(clean_text)\n",
        "docs.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21697    [item, 2, 02, results, operations, financial, ...\n",
              "21698    [item, 5, 07, submission, matters, vote, secur...\n",
              "21699    [item, 5, 02, departure, directors, certain, o...\n",
              "21700    [item, 2, 02, results, operations, financial, ...\n",
              "21701    [item, 5, 07, submission, matters, vote, secur...\n",
              "Name: texts, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBpXB37MloIv"
      },
      "source": [
        "# lemmatize documents\n",
        "def lemmatized_words(text):\n",
        "    lemm = nltk.stem.WordNetLemmatizer()\n",
        "    return list(map(lambda word: list(map(lemm.lemmatize, word)), docs))\n",
        "    \n",
        "lemmatized = lemmatized_words(docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRQfosA157Sa",
        "outputId": "97ca6144-a30e-4771-a793-bd590441edb4"
      },
      "source": [
        "df.label2.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pos    12742\n",
              "neg     8960\n",
              "Name: label2, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGh8IFRtl6AO"
      },
      "source": [
        "# Split into train and test data\n",
        "X_train, X_test, y_train, y_test, docs_train, docs_test = train_test_split(X, y, lemmatized,\n",
        "                                                    stratify=y, \n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1DffTS9mmBr"
      },
      "source": [
        "# standardize volatility index and market cap by mean and standard deviation (standardize train and test sets separately)\n",
        "x_scaler = StandardScaler()\n",
        "X_train[\"VIX\"] = x_scaler.fit_transform(np.array(X_train[\"VIX\"]).reshape(-1,1))\n",
        "X_test[\"VIX\"] = x_scaler.transform(np.array(X_test[\"VIX\"]).reshape(-1,1))\n",
        "X_train[\"Mkt_Cap\"] = x_scaler.fit_transform(np.array(X_train[\"Mkt_Cap\"]).reshape(-1,1))\n",
        "X_test[\"Mkt_Cap\"] = x_scaler.transform(np.array(X_test[\"Mkt_Cap\"]).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2dPXcZBnASA"
      },
      "source": [
        "# define BoW transformer, set max_features to 4000 to balance the dimensions with numerical features\n",
        "bow_transform = CountVectorizer(tokenizer=lambda doc: doc, max_features=4000, ngram_range=[1,3], lowercase=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neqfl0ETnTXI"
      },
      "source": [
        "#transform documents\n",
        "X_tr_bow = bow_transform.fit_transform(docs_train)\n",
        "X_te_bow = bow_transform.transform(docs_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrRp3MfXncMf",
        "outputId": "952c8a04-cc01-45ac-a94e-07ee73647ce4"
      },
      "source": [
        "X_tr_bow.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17361, 4000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MhcPGY-nrdg"
      },
      "source": [
        "#concatenate BoW features with numerical features (convert Bow features to dense array first)\n",
        "X_tr_bow_ft = np.concatenate((X_tr_bow.toarray(), np.array(X_train)), axis = 1)\n",
        "X_te_bow_ft = np.concatenate((X_te_bow.toarray(), np.array(X_test)), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uge9nkh6n-X9"
      },
      "source": [
        "# define Tf-idf transformer, set max_features to 4000 to balance the dimensions with numerical features\n",
        "tfidf_transform = TfidfVectorizer(tokenizer=lambda doc: doc, max_features=4000, ngram_range=[1,3], lowercase=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmoMswn4n-a-"
      },
      "source": [
        "#transform documents\n",
        "X_tr_tfidf = tfidf_transform.fit_transform(docs_train)\n",
        "X_te_tfidf = tfidf_transform.transform(docs_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abhBafD5n-dX"
      },
      "source": [
        "#concatenate Tf-idf features with numerical features (convert Tf-idf features to dense array first)\n",
        "X_tr_tfidf_ft = np.concatenate((X_tr_tfidf.toarray(), np.array(X_train)), axis = 1)\n",
        "X_te_tfidf_ft = np.concatenate((X_te_tfidf.toarray(), np.array(X_test)), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5ym3cFwnw6z"
      },
      "source": [
        "# define logistic regression classifier\n",
        "def simple_logistic_classify(X_tr, y_tr, X_test, y_test, description, _C=1.0):\n",
        "    model = LogisticRegression(C=_C).fit(X_tr, y_tr)\n",
        "    score = model.score(X_test, y_test)\n",
        "    print('Test Score with', description, 'features', score)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqmmnRd56PQW",
        "outputId": "51cc04b4-2bb4-48df-d155-4359ca484aa8"
      },
      "source": [
        "# fit the model to (BoW + numerical) and (Tf-idf + numerical) features\n",
        "model_bow = simple_logistic_classify(X_tr_bow_ft, y_train, X_te_bow_ft, y_test, 'bow')\n",
        "model_tfidf = simple_logistic_classify(X_tr_tfidf_ft, y_train, X_te_tfidf_ft, y_test, 'tf-idf')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Score with bow features 0.7242570836212854\n",
            "Test Score with tf-idf features 0.7357751670122091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DPqVeAo6aue"
      },
      "source": [
        "# Hyperparameter tuning\n",
        "\n",
        "# grid search parameters\n",
        "param_grid_ = [{'C': [1e-5, 1e-3, 1e-1, 1e0, 1e1, 1e2], 'penalty':[\"l1\", \"l2\", \"elasticnet\"]}]\n",
        "\n",
        "#create grid search with 5-fold cross validation\n",
        "bow_search = sklearn.model_selection.GridSearchCV(LogisticRegression(), cv=5, param_grid=param_grid_)\n",
        "tfidf_search = sklearn.model_selection.GridSearchCV(LogisticRegression(), cv=5,\n",
        "                                   param_grid=param_grid_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZa2plhj6dno",
        "outputId": "189f095c-1256-4f34-f56d-cf2155b7647f"
      },
      "source": [
        "bow_search.fit(X_tr_bow_ft, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'C': [1e-05, 0.001, 0.1, 1.0, 10.0, 100.0],\n",
              "                          'penalty': ['l1', 'l2', 'elasticnet']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_Vak0h86dro",
        "outputId": "0c95fdc4-72f6-4b09-ca41-9b7a9a267118"
      },
      "source": [
        "bow_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5PZXs_o6du5",
        "outputId": "7d964d24-9b35-4cee-9f86-065b4eb72168"
      },
      "source": [
        "bow_search.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7233454821327395"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8mKhjzg6dyk"
      },
      "source": [
        "bow_pred = bow_search.predict(X_te_bow_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsJpZ0RL6qbc",
        "outputId": "1ae1fb7f-fc60-492b-b119-74d9d243dd7e"
      },
      "source": [
        "print(classification_report(y_test, bow_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.67      0.65      0.66      1792\n",
            "         pos       0.76      0.78      0.77      2549\n",
            "\n",
            "    accuracy                           0.73      4341\n",
            "   macro avg       0.72      0.71      0.72      4341\n",
            "weighted avg       0.72      0.73      0.72      4341\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk_J4DJ46qen",
        "outputId": "751604be-8157-4107-c21b-2f5a5cc44c67"
      },
      "source": [
        "tfidf_search.fit(X_tr_tfidf_ft, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'C': [1e-05, 0.001, 0.1, 1.0, 10.0, 100.0],\n",
              "                          'penalty': ['l1', 'l2', 'elasticnet']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqNij4BQ6qjC",
        "outputId": "3a59daba-6850-4dff-fd16-1a006d93383c"
      },
      "source": [
        "tfidf_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcYMmESK6qmp",
        "outputId": "f95eb7fa-c0cb-46bf-e050-9483b622898c"
      },
      "source": [
        "tfidf_search.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7399341330952005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze87wK7T6qpw"
      },
      "source": [
        "tfidf_pred = tfidf_search.predict(X_te_tfidf_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffk2LsnR6d1f",
        "outputId": "de57334e-9de2-4182-c97d-fa4c445692a8"
      },
      "source": [
        "print(classification_report(y_test, tfidf_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.72      0.58      0.64      1792\n",
            "         pos       0.74      0.85      0.79      2549\n",
            "\n",
            "    accuracy                           0.74      4341\n",
            "   macro avg       0.73      0.71      0.72      4341\n",
            "weighted avg       0.73      0.74      0.73      4341\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TsfEwO9qVDh"
      },
      "source": [
        "### Multi-Class Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO3AuMIuqL4z"
      },
      "source": [
        "y = df['label3']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maOiFW5StduN"
      },
      "source": [
        "We have to repeat the process, because classes (split&stratification) changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGS-6Ifir4_E"
      },
      "source": [
        "# Split into train and test data\n",
        "X_train, X_test, y_train, y_test, docs_train, docs_test = train_test_split(X, y, lemmatized,\n",
        "                                                    stratify=y, \n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fxNMgu6r7Eu"
      },
      "source": [
        "X_train[\"VIX\"] = x_scaler.fit_transform(np.array(X_train[\"VIX\"]).reshape(-1,1))\n",
        "X_test[\"VIX\"] = x_scaler.transform(np.array(X_test[\"VIX\"]).reshape(-1,1))\n",
        "X_train[\"Mkt_Cap\"] = x_scaler.fit_transform(np.array(X_train[\"Mkt_Cap\"]).reshape(-1,1))\n",
        "X_test[\"Mkt_Cap\"] = x_scaler.transform(np.array(X_test[\"Mkt_Cap\"]).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHmOtZ5dsDgV"
      },
      "source": [
        "#transform documents\n",
        "X_tr_tfidf = tfidf_transform.fit_transform(docs_train)\n",
        "X_te_tfidf = tfidf_transform.transform(docs_test)\n",
        "X_tr_bow = bow_transform.fit_transform(docs_train)\n",
        "X_te_bow = bow_transform.transform(docs_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh8G0QeRski-"
      },
      "source": [
        "#concatenate text vectors with numerical features (convert sparse matrix to dense matrix first)\n",
        "X_tr_tfidf_ft = np.concatenate((X_tr_tfidf.toarray(), np.array(X_train)), axis = 1)\n",
        "X_te_tfidf_ft = np.concatenate((X_te_tfidf.toarray(), np.array(X_test)), axis = 1)\n",
        "X_tr_bow_ft = np.concatenate((X_tr_bow.toarray(), np.array(X_train)), axis = 1)\n",
        "X_te_bow_ft = np.concatenate((X_te_bow.toarray(), np.array(X_test)), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GKPvSFl_hso"
      },
      "source": [
        "# define logistic regression classifier\n",
        "def simple_logistic_classify(X_tr, y_tr, X_test, y_test, description, _C=1.0):\n",
        "    model = LogisticRegression(C=_C, multi_class=\"multinomial\").fit(X_tr, y_tr)\n",
        "    score = model.score(X_test, y_test)\n",
        "    print('Test Score with', description, 'features', score)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXRR49YTaiG7",
        "outputId": "bcdb6fdf-3dca-4621-bddd-ee79801fe5d0"
      },
      "source": [
        "# fit the model to (BoW + numerical) and (Tf-idf + numerical) features\n",
        "model_bow = simple_logistic_classify(X_tr_bow_ft, y_train, X_te_bow_ft, y_test, 'bow')\n",
        "model_tfidf = simple_logistic_classify(X_tr_tfidf_ft, y_train, X_te_tfidf_ft, y_test, 'tf-idf')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Score with bow features 0.6385625431928127\n",
            "Test Score with tf-idf features 0.65860400829302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3zc4nu8Gq82"
      },
      "source": [
        "# Hyperparameter tuning\n",
        "\n",
        "# grid search parameters\n",
        "param_grid_ = [{'C': [1e-5, 1e-3, 1e-1, 1e0, 1e1, 1e2], 'penalty':[\"l1\", \"l2\", \"elasticnet\"]}]\n",
        "\n",
        "#create grid search with 5-fold cross validation\n",
        "bow_search = sklearn.model_selection.GridSearchCV(LogisticRegression(), cv=5, param_grid=param_grid_)\n",
        "tfidf_search = sklearn.model_selection.GridSearchCV(LogisticRegression(), cv=5,\n",
        "                                   param_grid=param_grid_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hkmajv5a6tL",
        "outputId": "ea5b817b-d401-40b7-f5f0-f5f3686a5866"
      },
      "source": [
        "bow_search.fit(X_tr_bow_ft, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'C': [1e-05, 0.001, 0.1, 1.0, 10.0, 100.0],\n",
              "                          'penalty': ['l1', 'l2', 'elasticnet']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLMDGO9Ga6wz",
        "outputId": "bee2c06c-eb75-449c-dc05-99c32367b45a"
      },
      "source": [
        "bow_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx4y5c31a6zu",
        "outputId": "9bf85d0f-aa4a-474b-f2c6-77f416054853"
      },
      "source": [
        "bow_search.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6307811345189552"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGeiW1ria6_m"
      },
      "source": [
        "bow_pred = bow_search.predict(X_te_bow_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJlyqDYMa7Cx",
        "outputId": "4620ead5-f1ca-43fd-d6b1-d4b64b36c02e"
      },
      "source": [
        "print(classification_report(y_test, bow_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.51      0.43      0.47       690\n",
            "     neutral       0.69      0.78      0.73      2431\n",
            "    positive       0.57      0.47      0.52      1220\n",
            "\n",
            "    accuracy                           0.64      4341\n",
            "   macro avg       0.59      0.56      0.57      4341\n",
            "weighted avg       0.63      0.64      0.63      4341\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxnpz5Jka7F3",
        "outputId": "211ebb54-5f3e-47cb-bdf0-575e28e881ec"
      },
      "source": [
        "tfidf_search.fit(X_tr_tfidf_ft, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'C': [1e-05, 0.001, 0.1, 1.0, 10.0, 100.0],\n",
              "                          'penalty': ['l1', 'l2', 'elasticnet']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLMFTKMoa7I_",
        "outputId": "db6eb167-d1d5-4081-9e24-b8ddae24549b"
      },
      "source": [
        "tfidf_search.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlWP8cQXa7MJ",
        "outputId": "4c784ae4-b87f-43f2-e3f1-37968c94be69"
      },
      "source": [
        "tfidf_search.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6611945209987248"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNqondV1bVlx"
      },
      "source": [
        "tfidf_pred = tfidf_search.predict(X_te_tfidf_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH6mTaAHbVqR",
        "outputId": "14af5d57-7580-4da6-ca66-958a36b5e4b0"
      },
      "source": [
        "print(classification_report(y_test, tfidf_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.57      0.37      0.45       690\n",
            "     neutral       0.68      0.85      0.75      2431\n",
            "    positive       0.62      0.45      0.52      1220\n",
            "\n",
            "    accuracy                           0.66      4341\n",
            "   macro avg       0.62      0.55      0.57      4341\n",
            "weighted avg       0.65      0.66      0.64      4341\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}