{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_8K&Features.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phfeFGB-jQFH"
      },
      "source": [
        "## Logistic Regression - 8K Forms & Numerical Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNF2Q7L5jId7",
        "outputId": "0b0f30ae-528e-4360-ed5a-e0ce33102b07"
      },
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import sklearn.model_selection\n",
        "import sklearn.preprocessing as preproc\n",
        "from sklearn.feature_extraction import text\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuGFo3vqjuEc",
        "outputId": "1118c4a5-4b3a-468b-e8ba-2b9259a8c714"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "th5UFQNwj_D6",
        "outputId": "042cb049-4a5f-4d69-cde7-3b04e1146878"
      },
      "source": [
        "df = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/with_all_ft_clean.pkl\")\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>pct_change1</th>\n",
              "      <th>pct_change2</th>\n",
              "      <th>beta1</th>\n",
              "      <th>beta2</th>\n",
              "      <th>mkt_excess1</th>\n",
              "      <th>mkt_excess2</th>\n",
              "      <th>item 1.01</th>\n",
              "      <th>item 1.02</th>\n",
              "      <th>item 1.03</th>\n",
              "      <th>item 1.04</th>\n",
              "      <th>item 2.01</th>\n",
              "      <th>item 2.02</th>\n",
              "      <th>item 2.03</th>\n",
              "      <th>item 2.04</th>\n",
              "      <th>item 2.05</th>\n",
              "      <th>item 2.06</th>\n",
              "      <th>item 2.10</th>\n",
              "      <th>item 3.01</th>\n",
              "      <th>item 3.02</th>\n",
              "      <th>item 3.03</th>\n",
              "      <th>item 4.01</th>\n",
              "      <th>item 4.02</th>\n",
              "      <th>item 4.04</th>\n",
              "      <th>item 5.01</th>\n",
              "      <th>item 5.02</th>\n",
              "      <th>item 5.03</th>\n",
              "      <th>item 5.04</th>\n",
              "      <th>item 5.05</th>\n",
              "      <th>item 5.07</th>\n",
              "      <th>item 5.08</th>\n",
              "      <th>item 7.01</th>\n",
              "      <th>item 7.02</th>\n",
              "      <th>item 8.01</th>\n",
              "      <th>item 9.01</th>\n",
              "      <th>item 9.02</th>\n",
              "      <th>VIX</th>\n",
              "      <th>label1</th>\n",
              "      <th>label2</th>\n",
              "      <th>SHRCD_12.0</th>\n",
              "      <th>SHRCD_14.0</th>\n",
              "      <th>SHRCD_18.0</th>\n",
              "      <th>SHRCD_21.0</th>\n",
              "      <th>SHRCD_31.0</th>\n",
              "      <th>SHRCD_41.0</th>\n",
              "      <th>SHRCD_44.0</th>\n",
              "      <th>SHRCD_48.0</th>\n",
              "      <th>SHRCD_71.0</th>\n",
              "      <th>SHRCD_72.0</th>\n",
              "      <th>SHRCD_73.0</th>\n",
              "      <th>SHRCD_74.0</th>\n",
              "      <th>ind_21</th>\n",
              "      <th>ind_22</th>\n",
              "      <th>ind_23</th>\n",
              "      <th>ind_31</th>\n",
              "      <th>ind_32</th>\n",
              "      <th>ind_33</th>\n",
              "      <th>ind_42</th>\n",
              "      <th>ind_44</th>\n",
              "      <th>ind_45</th>\n",
              "      <th>ind_48</th>\n",
              "      <th>ind_49</th>\n",
              "      <th>ind_51</th>\n",
              "      <th>ind_52</th>\n",
              "      <th>ind_53</th>\n",
              "      <th>ind_54</th>\n",
              "      <th>ind_55</th>\n",
              "      <th>ind_56</th>\n",
              "      <th>ind_61</th>\n",
              "      <th>ind_62</th>\n",
              "      <th>ind_71</th>\n",
              "      <th>ind_72</th>\n",
              "      <th>ind_81</th>\n",
              "      <th>ind_na</th>\n",
              "      <th>EXCHCD_1.0</th>\n",
              "      <th>EXCHCD_2.0</th>\n",
              "      <th>EXCHCD_3.0</th>\n",
              "      <th>EXCHCD_4.0</th>\n",
              "      <th>Mkt_Cap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Item 2.02\\nResults of Operations and Financial...</td>\n",
              "      <td>0.039772</td>\n",
              "      <td>0.018824</td>\n",
              "      <td>0.1235</td>\n",
              "      <td>0.12100</td>\n",
              "      <td>0.039502</td>\n",
              "      <td>0.017531</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>16.14</td>\n",
              "      <td>pos</td>\n",
              "      <td>pos</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>86355.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Item 2.02 Results of Operations and Financial ...</td>\n",
              "      <td>0.005894</td>\n",
              "      <td>0.019647</td>\n",
              "      <td>0.9098</td>\n",
              "      <td>0.91085</td>\n",
              "      <td>-0.003435</td>\n",
              "      <td>0.005013</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>20.47</td>\n",
              "      <td>pos</td>\n",
              "      <td>pos</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125102.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ITEM 1.01.\\nENTRY INTO A MATERIAL DEFINITIVE A...</td>\n",
              "      <td>-0.019268</td>\n",
              "      <td>-0.019268</td>\n",
              "      <td>0.8742</td>\n",
              "      <td>0.87420</td>\n",
              "      <td>-0.013888</td>\n",
              "      <td>-0.013888</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>19.07</td>\n",
              "      <td>neg</td>\n",
              "      <td>neg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>126812.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ITEM 1.01.\\nENTRY INTO A MATERIAL DEFINITIVE A...</td>\n",
              "      <td>0.077505</td>\n",
              "      <td>0.035918</td>\n",
              "      <td>0.8901</td>\n",
              "      <td>0.88485</td>\n",
              "      <td>0.076161</td>\n",
              "      <td>0.027620</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>16.14</td>\n",
              "      <td>pos</td>\n",
              "      <td>pos</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>139273.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ITEM 1.01.\\nENTRY INTO A MATERIAL DEFINITIVE A...</td>\n",
              "      <td>0.076013</td>\n",
              "      <td>0.076013</td>\n",
              "      <td>0.9225</td>\n",
              "      <td>0.92250</td>\n",
              "      <td>0.070040</td>\n",
              "      <td>0.070040</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>13.51</td>\n",
              "      <td>pos</td>\n",
              "      <td>pos</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>144649.28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texts  ...    Mkt_Cap\n",
              "0  Item 2.02\\nResults of Operations and Financial...  ...   86355.36\n",
              "1  Item 2.02 Results of Operations and Financial ...  ...  125102.08\n",
              "2  ITEM 1.01.\\nENTRY INTO A MATERIAL DEFINITIVE A...  ...  126812.46\n",
              "3  ITEM 1.01.\\nENTRY INTO A MATERIAL DEFINITIVE A...  ...  139273.80\n",
              "4  ITEM 1.01.\\nENTRY INTO A MATERIAL DEFINITIVE A...  ...  144649.28\n",
              "\n",
              "[5 rows x 79 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXOVw9hQjxY_"
      },
      "source": [
        "def label1(row):\n",
        "    if row[\"pct_change1\"] > row[\"beta1\"]*row[\"mkt_excess1\"]:\n",
        "        return \"pos\"\n",
        "    else:\n",
        "        return \"neg\"\n",
        "\n",
        "def label2(row):\n",
        "    if row[\"pct_change2\"] > row[\"beta2\"]*row[\"mkt_excess2\"]:\n",
        "        return \"pos\"\n",
        "    else:\n",
        "        return \"neg\"\n",
        "\n",
        "def label3(row):\n",
        "    if row[\"pct_change2\"] > row[\"beta2\"]*row[\"mkt_excess2\"] + 0.005:\n",
        "        return \"positive\"\n",
        "    elif row[\"pct_change2\"] < row[\"beta2\"]*row[\"mkt_excess2\"] - 0.005:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxbvLasbkT1-"
      },
      "source": [
        "df[\"label1\"] = df.apply(label1, axis = 1)\n",
        "df[\"label2\"] = df.apply(label2, axis = 1)\n",
        "df[\"label3\"] = df.apply(label3, axis = 1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgsxsQcxkaE4"
      },
      "source": [
        "# get column names of categorical features\n",
        "item_list = [i for i in df.columns if not i.find(\"item\")]\n",
        "ind_list = [i for i in df.columns if not i.find(\"ind\")]\n",
        "shrcd_list = [i for i in df.columns if not i.find(\"SHRCD\")]\n",
        "exc_list = [i for i in df.columns if not i.find(\"EXCHCD\")]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_gGYOfokhvx"
      },
      "source": [
        "# combine all feature column names\n",
        "cols = ['VIX', \"Mkt_Cap\"]\n",
        "cols.extend(item_list)\n",
        "cols.extend(ind_list)\n",
        "cols.extend(shrcd_list)\n",
        "cols.extend(exc_list)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTpZgNpqklJf"
      },
      "source": [
        "# Separate into features, documents and label\n",
        "cols = ['VIX', \"Mkt_Cap\"]\n",
        "cols.extend(item_list)\n",
        "cols.extend(ind_list)\n",
        "cols.extend(shrcd_list)\n",
        "cols.extend(exc_list)\n",
        "\n",
        "X = df[cols]\n",
        "\n",
        "docs = df['texts']\n",
        "\n",
        "y = df['label2']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3O8_m81lOa1"
      },
      "source": [
        "#### Process texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5UHGtORk-Id"
      },
      "source": [
        "contractions = { \n",
        "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
        "\"aren't\": \"are not / am not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had / he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he shall / he will\",\n",
        "\"he'll've\": \"he shall have / he will have\",\n",
        "\"he's\": \"he has / he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how has / how is / how does\",\n",
        "\"I'd\": \"I had / I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I shall / I will\",\n",
        "\"I'll've\": \"I shall have / I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had / it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it shall / it will\",\n",
        "\"it'll've\": \"it shall have / it will have\",\n",
        "\"it's\": \"it has / it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she had / she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she shall / she will\",\n",
        "\"she'll've\": \"she shall have / she will have\",\n",
        "\"she's\": \"she has / she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as / so is\",\n",
        "\"that'd\": \"that would / that had\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that has / that is\",\n",
        "\"there'd\": \"there had / there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there has / there is\",\n",
        "\"they'd\": \"they had / they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they shall / they will\",\n",
        "\"they'll've\": \"they shall have / they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had / we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what shall / what will\",\n",
        "\"what'll've\": \"what shall have / what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what has / what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when has / when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where has / where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who shall / who will\",\n",
        "\"who'll've\": \"who shall have / who will have\",\n",
        "\"who's\": \"who has / who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why has / why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had / you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you shall / you will\",\n",
        "\"you'll've\": \"you shall have / you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDBVnUDMlMMo"
      },
      "source": [
        "def clean_text(text, remove_stopwords = True):\n",
        "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
        "    \n",
        "    # Convert words to lower case\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Replace contractions with their longer forms \n",
        "    if True:\n",
        "        text = text.split()\n",
        "        new_text = []\n",
        "        for word in text:\n",
        "            if word in contractions:\n",
        "                new_text.append(contractions[word])\n",
        "            else:\n",
        "                new_text.append(word)\n",
        "        text = \" \".join(new_text)\n",
        "    \n",
        "    # Format words and remove unwanted characters\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\<a href', ' ', text)\n",
        "    text = re.sub(r'&amp;', '', text) \n",
        "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
        "    text = re.sub(r'<br />', ' ', text)\n",
        "    text = re.sub(r'\\'', ' ', text)\n",
        "    \n",
        "    # remove stop words\n",
        "    if remove_stopwords:\n",
        "        text = text.split()\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        text = [w for w in text if not w in stops]\n",
        "        text = \" \".join(text)\n",
        "\n",
        "    # Tokenize each word\n",
        "    text =  nltk.WordPunctTokenizer().tokenize(text)\n",
        "        \n",
        "    return text"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bAJ7dbQlWya",
        "outputId": "304024f2-83a2-4078-8f55-248bf0c6b18a"
      },
      "source": [
        "# apply clean function to documents\n",
        "docs = df.texts.apply(clean_text)\n",
        "docs.tail()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21697    [item, 2, 02, results, operations, financial, ...\n",
              "21698    [item, 5, 07, submission, matters, vote, secur...\n",
              "21699    [item, 5, 02, departure, directors, certain, o...\n",
              "21700    [item, 2, 02, results, operations, financial, ...\n",
              "21701    [item, 5, 07, submission, matters, vote, secur...\n",
              "Name: texts, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBpXB37MloIv"
      },
      "source": [
        "# lemmatize documents\n",
        "def lemmatized_words(text):\n",
        "    lemm = nltk.stem.WordNetLemmatizer()\n",
        "    return list(map(lambda word: list(map(lemm.lemmatize, word)), docs))\n",
        "    \n",
        "lemmatized = lemmatized_words(docs)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGh8IFRtl6AO"
      },
      "source": [
        "# Split into train and test data\n",
        "X_train, X_test, y_train, y_test, docs_train, docs_test = train_test_split(X, y, lemmatized,\n",
        "                                                    stratify=y, \n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state = 20)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1DffTS9mmBr"
      },
      "source": [
        "# standardize volatility index and market cap by mean and standard deviation (standardize train and test sets separately)\n",
        "x_scaler = StandardScaler()\n",
        "X_train[\"VIX\"] = x_scaler.fit_transform(np.array(X_train[\"VIX\"]).reshape(-1,1))\n",
        "X_test[\"VIX\"] = x_scaler.transform(np.array(X_test[\"VIX\"]).reshape(-1,1))\n",
        "X_train[\"Mkt_Cap\"] = x_scaler.fit_transform(np.array(X_train[\"Mkt_Cap\"]).reshape(-1,1))\n",
        "X_test[\"Mkt_Cap\"] = x_scaler.transform(np.array(X_test[\"Mkt_Cap\"]).reshape(-1,1))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2dPXcZBnASA"
      },
      "source": [
        "# define BoW transformer, set max_features to 4000 to balance the dimensions with numerical features\n",
        "bow_transform = CountVectorizer(tokenizer=lambda doc: doc, max_features=4000, ngram_range=[1,3], lowercase=False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neqfl0ETnTXI"
      },
      "source": [
        "#transform documents\n",
        "X_tr_bow = bow_transform.fit_transform(docs_train)\n",
        "X_te_bow = bow_transform.transform(docs_test)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrRp3MfXncMf",
        "outputId": "eb3aec81-b67b-42a8-951a-09622aa32764"
      },
      "source": [
        "X_tr_bow.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17361, 4000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MhcPGY-nrdg"
      },
      "source": [
        "#concatenate BoW features with numerical features (convert Bow features to dense array first)\n",
        "X_tr_bow_ft = np.concatenate((X_tr_bow.toarray(), np.array(X_train)), axis = 1)\n",
        "X_te_bow_ft = np.concatenate((X_te_bow.toarray(), np.array(X_test)), axis = 1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uge9nkh6n-X9"
      },
      "source": [
        "# define Tf-idf transformer, set max_features to 4000 to balance the dimensions with numerical features\n",
        "tfidf_transform = TfidfVectorizer(tokenizer=lambda doc: doc, max_features=4000, ngram_range=[1,3], lowercase=False)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmoMswn4n-a-"
      },
      "source": [
        "#transform documents\n",
        "X_tr_tfidf = tfidf_transform.fit_transform(docs_train)\n",
        "X_te_tfidf = tfidf_transform.transform(docs_test)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abhBafD5n-dX"
      },
      "source": [
        "#concatenate Tf-idf features with numerical features (convert Tf-idf features to dense array first)\n",
        "X_tr_tfidf_ft = np.concatenate((X_tr_tfidf.toarray(), np.array(X_train)), axis = 1)\n",
        "X_te_tfidf_ft = np.concatenate((X_te_tfidf.toarray(), np.array(X_test)), axis = 1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5ym3cFwnw6z"
      },
      "source": [
        "# define logistic regression classifier\n",
        "def simple_logistic_classify(X_tr, y_tr, X_test, y_test, description, _C=1.0):\n",
        "    model = LogisticRegression(C=_C).fit(X_tr, y_tr)\n",
        "    score = model.score(X_test, y_test)\n",
        "    print('Test Score with', description, 'features', score)\n",
        "    return model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwtvH5dpn1Mz",
        "outputId": "2c5f4795-a40a-4454-bef4-bfb85cbdade5"
      },
      "source": [
        "# fit the model to (BoW + numerical) and (Tf-idf + numerical) features\n",
        "model_bow = simple_logistic_classify(X_tr_bow_ft, y_train, X_te_bow_ft, y_test, 'bow')\n",
        "model_tfidf = simple_logistic_classify(X_tr_tfidf_ft, y_train, X_te_tfidf_ft, y_test, 'tf-idf')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Score with bow features 0.5807417645703755\n",
            "Test Score with tf-idf features 0.6056208246947707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6U1WbqXoqRJ"
      },
      "source": [
        "# Hyperparameter tuning\n",
        "\n",
        "# grid search parameters\n",
        "param_grid_ = [{'C': [1e-5, 1e-3, 1e-1, 1e0, 1e1, 1e2], 'penalty':[\"l1\", \"l2\", \"elasticnet\"]}]\n",
        "\n",
        "#create grid search with 5-fold cross validation\n",
        "bow_search = sklearn.model_selection.GridSearchCV(LogisticRegression(), cv=5, param_grid=param_grid_)\n",
        "tfidf_search = sklearn.model_selection.GridSearchCV(LogisticRegression(), cv=5,\n",
        "                                   param_grid=param_grid_)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDUlDx9ypSuB",
        "outputId": "5bb7f792-5d34-4da0-9e87-d9ef1a44bc76"
      },
      "source": [
        "bow_search.fit(X_tr_bow_ft, y_train)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'C': [1e-05, 0.001, 0.1, 1.0, 10.0, 100.0],\n",
              "                          'penalty': ['l1', 'l2', 'elasticnet']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kxSYevKpkP4",
        "outputId": "b474d83f-5c40-40aa-835a-10d86977bcc0"
      },
      "source": [
        "bow_search.best_score_"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5969705403501137"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zj6P4AGpqNF",
        "outputId": "ea4628d8-a8c1-485a-9276-337be0e383c8"
      },
      "source": [
        "tfidf_search.fit(X_tr_tfidf_ft, y_train)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'C': [1e-05, 0.001, 0.1, 1.0, 10.0, 100.0],\n",
              "                          'penalty': ['l1', 'l2', 'elasticnet']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V06ro_YSpswk",
        "outputId": "f131ab92-0ac4-42d7-c406-59148163f1ed"
      },
      "source": [
        "tfidf_search.best_score_"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6077993534056667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "166pcj58pvwi"
      },
      "source": [
        "# get best models' predictions\n",
        "bow_pred = bow_search.predict(X_te_bow_ft)\n",
        "tfidf_pred = tfidf_search.predict(X_te_tfidf_ft)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47KnWgK4p3F0",
        "outputId": "8af795b0-b26f-4296-d40d-3e7365296791"
      },
      "source": [
        "print(classification_report(y_test, bow_pred))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.57      0.34      0.43      1935\n",
            "         pos       0.60      0.79      0.68      2406\n",
            "\n",
            "    accuracy                           0.59      4341\n",
            "   macro avg       0.59      0.57      0.56      4341\n",
            "weighted avg       0.59      0.59      0.57      4341\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn7UMz1EqCOE",
        "outputId": "655966b6-7f29-48a8-8391-8fb595e1db51"
      },
      "source": [
        "print(classification_report(y_test, tfidf_pred))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.58      0.44      0.50      1935\n",
            "         pos       0.62      0.74      0.67      2406\n",
            "\n",
            "    accuracy                           0.61      4341\n",
            "   macro avg       0.60      0.59      0.59      4341\n",
            "weighted avg       0.60      0.61      0.60      4341\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TsfEwO9qVDh"
      },
      "source": [
        "### Multi-Class Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO3AuMIuqL4z"
      },
      "source": [
        "y = df['label3']"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maOiFW5StduN"
      },
      "source": [
        "We have to repeat the process, because classes (split&stratification) changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGS-6Ifir4_E"
      },
      "source": [
        "# Split into train and test data\n",
        "X_train, X_test, y_train, y_test, docs_train, docs_test = train_test_split(X, y, lemmatized,\n",
        "                                                    stratify=y, \n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state = 20)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fxNMgu6r7Eu"
      },
      "source": [
        "X_train[\"VIX\"] = x_scaler.fit_transform(np.array(X_train[\"VIX\"]).reshape(-1,1))\n",
        "X_test[\"VIX\"] = x_scaler.transform(np.array(X_test[\"VIX\"]).reshape(-1,1))\n",
        "X_train[\"Mkt_Cap\"] = x_scaler.fit_transform(np.array(X_train[\"Mkt_Cap\"]).reshape(-1,1))\n",
        "X_test[\"Mkt_Cap\"] = x_scaler.transform(np.array(X_test[\"Mkt_Cap\"]).reshape(-1,1))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHmOtZ5dsDgV"
      },
      "source": [
        "#transform documents\n",
        "X_tr_tfidf = tfidf_transform.fit_transform(docs_train)\n",
        "X_te_tfidf = tfidf_transform.transform(docs_test)\n",
        "X_tr_bow = bow_transform.fit_transform(docs_train)\n",
        "X_te_bow = bow_transform.transform(docs_test)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh8G0QeRski-"
      },
      "source": [
        "#concatenate text vectors with numerical features (convert sparse matrix to dense matrix first)\n",
        "X_tr_tfidf_ft = np.concatenate((X_tr_tfidf.toarray(), np.array(X_train)), axis = 1)\n",
        "X_te_tfidf_ft = np.concatenate((X_te_tfidf.toarray(), np.array(X_test)), axis = 1)\n",
        "X_tr_bow_ft = np.concatenate((X_tr_bow.toarray(), np.array(X_train)), axis = 1)\n",
        "X_te_bow_ft = np.concatenate((X_te_bow.toarray(), np.array(X_test)), axis = 1)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skU4vXntssUk"
      },
      "source": [
        "# define MULTINOMIAL logistic regression classifier\n",
        "def simple_logistic_classify(X_tr, y_tr, X_test, y_test, description, _C=1.0):\n",
        "    model = LogisticRegression(C=_C, multi_class=\"multinomial\").fit(X_tr, y_tr)\n",
        "    score = model.score(X_test, y_test)\n",
        "    print('Test Score with', description, 'features', score)\n",
        "    return model"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gpLDB72uIVX",
        "outputId": "6cd27635-446b-40a1-8e8f-569815f57f63"
      },
      "source": [
        "# fit the model\n",
        "model_bow = simple_logistic_classify(X_tr_bow_ft, y_train, X_te_bow_ft, y_test, 'bow')\n",
        "model_tfidf = simple_logistic_classify(X_tr_tfidf_ft, y_train, X_te_tfidf_ft, y_test, 'tf-idf')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Score with bow features 0.36788758350610457\n",
            "Test Score with tf-idf features 0.47500575904169545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aBUq6iVvEp9"
      },
      "source": [
        "tfidf_pred = model_tfidf.predict(X_te_tfidf_ft)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHkI8sj-vEtl",
        "outputId": "7933ccaa-7bff-4332-ea8a-ea1c669fa404"
      },
      "source": [
        "print(classification_report(y_test, tfidf_pred))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.47      0.40      0.43      1289\n",
            "     neutral       0.46      0.41      0.43      1364\n",
            "    positive       0.48      0.59      0.53      1688\n",
            "\n",
            "    accuracy                           0.48      4341\n",
            "   macro avg       0.47      0.46      0.47      4341\n",
            "weighted avg       0.47      0.48      0.47      4341\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}