{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GloVe_LSTM_8K.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an3gMo7JLg9y"
      },
      "source": [
        "## Glove + LSTM model with 8-K forms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XshiOfDjMrsR"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext.legacy.data import Field, LabelField, TabularDataset, BucketIterator\n",
        "import torch.nn as nn"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4qqZ6zULdVq",
        "outputId": "4fc9de4e-2918-403a-b18e-3563c51a7446"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "ImGCLLFfLu7m",
        "outputId": "b1ce9b96-f964-4d88-cf3c-8afc6e716dc0"
      },
      "source": [
        "df = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/wholething.pkl\")\n",
        "df.dropna(inplace=True)\n",
        "df = df.reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>symbol</th>\n",
              "      <th>cik</th>\n",
              "      <th>form</th>\n",
              "      <th>access_number</th>\n",
              "      <th>filed_date</th>\n",
              "      <th>accepted_date</th>\n",
              "      <th>report_url</th>\n",
              "      <th>filing_url</th>\n",
              "      <th>string</th>\n",
              "      <th>texts</th>\n",
              "      <th>lens</th>\n",
              "      <th>pct_change1</th>\n",
              "      <th>pct_change2</th>\n",
              "      <th>beta1</th>\n",
              "      <th>beta2</th>\n",
              "      <th>mkt_excess1</th>\n",
              "      <th>mkt_excess2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NICK</td>\n",
              "      <td>1000045</td>\n",
              "      <td>8-K</td>\n",
              "      <td>0001193125-19-024617</td>\n",
              "      <td>2019-02-01</td>\n",
              "      <td>2019-02-01 06:31:07</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/100004...</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/100004...</td>\n",
              "      <td>8-K 1 d675768d8k.htm FORM 8-K\\n    UNITED STAT...</td>\n",
              "      <td>Item 2.02\\nResults of Operations and Financial...</td>\n",
              "      <td>182</td>\n",
              "      <td>0.039772</td>\n",
              "      <td>0.018824</td>\n",
              "      <td>0.1235</td>\n",
              "      <td>0.12100</td>\n",
              "      <td>0.039502</td>\n",
              "      <td>0.017531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MFIN</td>\n",
              "      <td>1000209</td>\n",
              "      <td>8-K</td>\n",
              "      <td>0001193125-19-004285</td>\n",
              "      <td>2019-01-08</td>\n",
              "      <td>2019-01-08 09:10:35</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/100020...</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/100020...</td>\n",
              "      <td>8-K 1 d685338d8k.htm 8-K\\n    UNITED STATES\\nS...</td>\n",
              "      <td>Item 2.02 Results of Operations and Financial ...</td>\n",
              "      <td>711</td>\n",
              "      <td>0.005894</td>\n",
              "      <td>0.019647</td>\n",
              "      <td>0.9098</td>\n",
              "      <td>0.91085</td>\n",
              "      <td>-0.003435</td>\n",
              "      <td>0.005013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MFIN</td>\n",
              "      <td>1000209</td>\n",
              "      <td>8-K</td>\n",
              "      <td>0001193125-19-007413</td>\n",
              "      <td>2019-01-11</td>\n",
              "      <td>2019-01-11 16:32:03</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/100020...</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/100020...</td>\n",
              "      <td>8-K 1 d682501d8k.htm FORM 8-K\\n    UNITED STAT...</td>\n",
              "      <td>ITEM 1.01.\\nENTRY INTO A MATERIAL DEFINITIVE A...</td>\n",
              "      <td>261</td>\n",
              "      <td>-0.019268</td>\n",
              "      <td>-0.019268</td>\n",
              "      <td>0.8742</td>\n",
              "      <td>0.87420</td>\n",
              "      <td>-0.013888</td>\n",
              "      <td>-0.013888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MFIN</td>\n",
              "      <td>1000209</td>\n",
              "      <td>8-K</td>\n",
              "      <td>0001193125-19-024926</td>\n",
              "      <td>2019-02-01</td>\n",
              "      <td>2019-02-01 08:50:35</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/100020...</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/100020...</td>\n",
              "      <td>8-K 1 d671008d8k.htm FORM 8-K\\n    UNITED STAT...</td>\n",
              "      <td>ITEM 1.01.\\nENTRY INTO A MATERIAL DEFINITIVE A...</td>\n",
              "      <td>257</td>\n",
              "      <td>0.077505</td>\n",
              "      <td>0.035918</td>\n",
              "      <td>0.8901</td>\n",
              "      <td>0.88485</td>\n",
              "      <td>0.076161</td>\n",
              "      <td>0.027620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MFIN</td>\n",
              "      <td>1000209</td>\n",
              "      <td>8-K</td>\n",
              "      <td>0001193125-19-047009</td>\n",
              "      <td>2019-02-21</td>\n",
              "      <td>2019-02-21 16:13:02</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/100020...</td>\n",
              "      <td>https://www.sec.gov/Archives/edgar/data/100020...</td>\n",
              "      <td>8-K 1 d711389d8k.htm 8-K\\n    UNITED STATES\\nS...</td>\n",
              "      <td>ITEM 1.01.\\nENTRY INTO A MATERIAL DEFINITIVE A...</td>\n",
              "      <td>257</td>\n",
              "      <td>0.076013</td>\n",
              "      <td>0.076013</td>\n",
              "      <td>0.9225</td>\n",
              "      <td>0.92250</td>\n",
              "      <td>0.070040</td>\n",
              "      <td>0.070040</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  symbol      cik form  ...    beta2 mkt_excess1 mkt_excess2\n",
              "0   NICK  1000045  8-K  ...  0.12100    0.039502    0.017531\n",
              "1   MFIN  1000209  8-K  ...  0.91085   -0.003435    0.005013\n",
              "2   MFIN  1000209  8-K  ...  0.87420   -0.013888   -0.013888\n",
              "3   MFIN  1000209  8-K  ...  0.88485    0.076161    0.027620\n",
              "4   MFIN  1000209  8-K  ...  0.92250    0.070040    0.070040\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDZIsl5WMn11"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2oYPG0yMw1D"
      },
      "source": [
        "def label1(row):\n",
        "    if row[\"pct_change1\"] > row[\"beta1\"]*row[\"mkt_excess1\"]:\n",
        "        return \"pos\"\n",
        "    else:\n",
        "        return \"neg\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se0rwYJbM4AU"
      },
      "source": [
        "def label2(row):\n",
        "    if row[\"pct_change2\"] > row[\"beta2\"]*row[\"mkt_excess2\"]:\n",
        "        return \"pos\"\n",
        "    else:\n",
        "        return \"neg\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvdJbb6HOzhS"
      },
      "source": [
        "df[\"label1\"] = df.apply(label1, axis = 1)\n",
        "df[\"label2\"] = df.apply(label2, axis = 1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "gKOSMqkhOFLc",
        "outputId": "cb55ab27-dc73-4502-9d46-b01efd0ac6d6"
      },
      "source": [
        "df = df[[\"texts\", \"label2\"]]\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>label2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Item 2.02\\nResults of Operations and Financial...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Item 2.02 Results of Operations and Financial ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ITEM 1.01.\\nENTRY INTO A MATERIAL DEFINITIVE A...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ITEM 1.01.\\nENTRY INTO A MATERIAL DEFINITIVE A...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ITEM 1.01.\\nENTRY INTO A MATERIAL DEFINITIVE A...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texts label2\n",
              "0  Item 2.02\\nResults of Operations and Financial...    pos\n",
              "1  Item 2.02 Results of Operations and Financial ...    pos\n",
              "2  ITEM 1.01.\\nENTRY INTO A MATERIAL DEFINITIVE A...    neg\n",
              "3  ITEM 1.01.\\nENTRY INTO A MATERIAL DEFINITIVE A...    pos\n",
              "4  ITEM 1.01.\\nENTRY INTO A MATERIAL DEFINITIVE A...    pos"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8S1xQhoOjo8"
      },
      "source": [
        "# save texts and labels\n",
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/data_lstm.csv')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiYBGSCWPEwp"
      },
      "source": [
        "# define fields for tabular dataset in directory\n",
        "TEXT = Field(tokenize=\"spacy\",lower = True, sequential=True, batch_first=True,include_lengths=True)\n",
        "LABEL = LabelField(dtype = torch.float,batch_first=True)\n",
        "fields = [(None, None),('text',TEXT), ('label', LABEL)]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeUPswtkPM_n"
      },
      "source": [
        "#call data from directory with Tabular Dataset and process with pipeline defined in fields\n",
        "data=TabularDataset(path = \"/content/drive/MyDrive/Colab Notebooks/data_lstm.csv\",format = 'csv',fields = fields,skip_header = True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK79iaCiPnYD",
        "outputId": "28743e16-6826-4d33-c63f-fd4f820d3b98"
      },
      "source": [
        "# a sequence with its label\n",
        "vars(data[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 'pos',\n",
              " 'text': ['item',\n",
              "  '2.02',\n",
              "  '\\n',\n",
              "  'results',\n",
              "  'of',\n",
              "  'operations',\n",
              "  'and',\n",
              "  'financial',\n",
              "  'condition',\n",
              "  '\\n',\n",
              "  'on',\n",
              "  'february',\n",
              "  '1',\n",
              "  ',',\n",
              "  '2019',\n",
              "  'nicholas',\n",
              "  'financial',\n",
              "  ',',\n",
              "  'inc.',\n",
              "  '(',\n",
              "  'the',\n",
              "  '“',\n",
              "  'company',\n",
              "  '”',\n",
              "  ')',\n",
              "  'issued',\n",
              "  'a',\n",
              "  'press',\n",
              "  'release',\n",
              "  'announcing',\n",
              "  'the',\n",
              "  'company',\n",
              "  '’s',\n",
              "  'financial',\n",
              "  'results',\n",
              "  'for',\n",
              "  'its',\n",
              "  'quarter',\n",
              "  'ended',\n",
              "  'december',\n",
              "  '31',\n",
              "  ',',\n",
              "  '2018',\n",
              "  '.',\n",
              "  'a',\n",
              "  'copy',\n",
              "  'of',\n",
              "  'this',\n",
              "  'press',\n",
              "  'release',\n",
              "  'is',\n",
              "  'attached',\n",
              "  'hereto',\n",
              "  'as',\n",
              "  'exhibit',\n",
              "  '99.1',\n",
              "  '.',\n",
              "  '\\n',\n",
              "  'the',\n",
              "  'information',\n",
              "  'included',\n",
              "  'in',\n",
              "  'this',\n",
              "  'current',\n",
              "  'report',\n",
              "  'on',\n",
              "  'form',\n",
              "  '8-k',\n",
              "  '(',\n",
              "  'including',\n",
              "  'exhibit',\n",
              "  '99.1',\n",
              "  'hereto',\n",
              "  ')',\n",
              "  'is',\n",
              "  'furnished',\n",
              "  'pursuant',\n",
              "  'to',\n",
              "  'this',\n",
              "  'item',\n",
              "  '2.02',\n",
              "  'and',\n",
              "  'shall',\n",
              "  'not',\n",
              "  'be',\n",
              "  'deemed',\n",
              "  'to',\n",
              "  'be',\n",
              "  '“',\n",
              "  'filed',\n",
              "  '”',\n",
              "  'for',\n",
              "  'the',\n",
              "  'purposes',\n",
              "  'of',\n",
              "  'section',\n",
              "  '18',\n",
              "  'of',\n",
              "  'the',\n",
              "  'securities',\n",
              "  'exchange',\n",
              "  'act',\n",
              "  'of',\n",
              "  '1934',\n",
              "  ',',\n",
              "  'as',\n",
              "  'amended',\n",
              "  ',',\n",
              "  'or',\n",
              "  'otherwise',\n",
              "  'subject',\n",
              "  'to',\n",
              "  'the',\n",
              "  'liabilities',\n",
              "  'of',\n",
              "  'that',\n",
              "  'section',\n",
              "  'or',\n",
              "  'sections',\n",
              "  '11',\n",
              "  'and',\n",
              "  '12(a)(2',\n",
              "  ')',\n",
              "  'of',\n",
              "  'the',\n",
              "  'securities',\n",
              "  'act',\n",
              "  'of',\n",
              "  '1933',\n",
              "  ',',\n",
              "  'as',\n",
              "  'amended',\n",
              "  '.',\n",
              "  'in',\n",
              "  'addition',\n",
              "  ',',\n",
              "  'the',\n",
              "  'information',\n",
              "  'included',\n",
              "  'in',\n",
              "  'this',\n",
              "  'current',\n",
              "  'report',\n",
              "  'on',\n",
              "  'form',\n",
              "  '8-k',\n",
              "  '(',\n",
              "  'including',\n",
              "  'exhibit',\n",
              "  '99.1',\n",
              "  'hereto',\n",
              "  ')',\n",
              "  'shall',\n",
              "  'not',\n",
              "  'be',\n",
              "  'incorporated',\n",
              "  'by',\n",
              "  'reference',\n",
              "  'into',\n",
              "  'any',\n",
              "  'filing',\n",
              "  'of',\n",
              "  'the',\n",
              "  'company',\n",
              "  ',',\n",
              "  'whether',\n",
              "  'made',\n",
              "  'before',\n",
              "  'or',\n",
              "  'after',\n",
              "  'the',\n",
              "  'date',\n",
              "  'hereof',\n",
              "  ',',\n",
              "  'regardless',\n",
              "  'of',\n",
              "  'any',\n",
              "  'general',\n",
              "  'incorporation',\n",
              "  'language',\n",
              "  'in',\n",
              "  'such',\n",
              "  'filing',\n",
              "  ',',\n",
              "  'unless',\n",
              "  'expressly',\n",
              "  'incorporated',\n",
              "  'by',\n",
              "  'specific',\n",
              "  'reference',\n",
              "  'into',\n",
              "  'such',\n",
              "  'filing',\n",
              "  '.',\n",
              "  '\\n  ',\n",
              "  'item',\n",
              "  '9.01',\n",
              "  '\\n',\n",
              "  'financial',\n",
              "  'statements',\n",
              "  'and',\n",
              "  'exhibits',\n",
              "  '\\n',\n",
              "  'exhibit',\n",
              "  'index',\n",
              "  '\\n  ',\n",
              "  'exhibit',\n",
              "  '   ',\n",
              "  'description',\n",
              "  '\\n',\n",
              "  '99.1',\n",
              "  '   ',\n",
              "  'press',\n",
              "  'release',\n",
              "  'dated',\n",
              "  'february',\n",
              "  '1',\n",
              "  ',',\n",
              "  '2019',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqPFZwIVRa_n"
      },
      "source": [
        "# split data into training and validation sets\n",
        "train_data, valid_data = data.split(split_ratio=0.8)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMf2nHwmRgFV",
        "outputId": "bc88e781-b43b-4069-f27b-13554f43b299"
      },
      "source": [
        "# build vocabulary from training set using 100 dimensional GloVe embeddings\n",
        "TEXT.build_vocab(train_data,min_freq=3,vectors = \"glove.6B.100d\")  \n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.35MB/s]                           \n",
            "100%|█████████▉| 399997/400000 [00:14<00:00, 28650.43it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkH-adjRRlK_"
      },
      "source": [
        "# set devide to \"cuda\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
        "\n",
        "#set batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "#Load an iterator\n",
        "train_iterator, valid_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch=True,\n",
        "    device = device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmsQb6aIbkJc"
      },
      "source": [
        "# define classifier\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    #define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout):\n",
        "        \n",
        "        #Constructor\n",
        "        super().__init__()          \n",
        "        \n",
        "        #embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        #lstm layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        \n",
        "        #dense layer\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        #activation function\n",
        "        self.act = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # pass sequences through embedding layer\n",
        "        embedded = self.embedding(text)\n",
        "      \n",
        "        #packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "            \n",
        "        #pass sequences through LSTM\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        \n",
        "        #concat the final forward and backward hidden state\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "                \n",
        "        #pass hidden state through fully connected layer\n",
        "        dense_outputs=self.fc(hidden)\n",
        "\n",
        "        #Final activation function\n",
        "        outputs=self.act(dense_outputs)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWuuemG3SigU"
      },
      "source": [
        "#define hyperparameters\n",
        "size_of_vocab = len(TEXT.vocab)\n",
        "embedding_dim = 100\n",
        "num_hidden_nodes = 32\n",
        "num_output_nodes = 1\n",
        "num_layers = 2\n",
        "bidirection = True\n",
        "dropout = 0.2\n",
        "\n",
        "#instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes,num_output_nodes, num_layers, \n",
        "                   bidirectional = True, dropout = dropout)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1OwwgYFSt62",
        "outputId": "ed430240-f937-4b39-9212-4b1d70595732"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "#Initialize the pretrained embedding\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(22654, 100)\n",
            "  (lstm): LSTM(100, 32, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (act): Sigmoid()\n",
            ")\n",
            "The model has 2,324,857 trainable parameters\n",
            "torch.Size([22654, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duqsV1OOSw5v"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTj4dJSmyeQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d79d42fe-742d-408c-beb2-ce18b3002ff7"
      },
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-4)\n",
        "\n",
        "#define the loss\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "#define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds)\n",
        "    \n",
        "    correct = (rounded_preds == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "#push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 399997/400000 [00:29<00:00, 28650.43it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BGdMZnDyor0"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    #initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    #set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        #resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        #retrieve text and no. of words\n",
        "        text, text_lengths = batch.text   \n",
        "        \n",
        "        #convert to 1D tensor\n",
        "        predictions = model(text, text_lengths).squeeze()  \n",
        "        \n",
        "        #compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        #compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        #backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        #update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        #loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIns65hzdpw_"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    #initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    #deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            #retrieve text and no. of words\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            #convert to 1d tensor\n",
        "            predictions = model(text, text_lengths).squeeze()\n",
        "            \n",
        "            #compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            #keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIPwsyM_TDyp",
        "outputId": "d4e57ba2-7292-4125-8b5c-ec59debe3106"
      },
      "source": [
        "N_EPOCHS = 15\n",
        "best_valid_loss = float('inf')\n",
        "best_valid_accuracy = 0\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    #train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    #evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "\n",
        "    if valid_acc > best_valid_accuracy:\n",
        "      best_valid_accuracy = valid_acc "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.689 | Train Acc: 53.64%\n",
            "\t Val. Loss: 0.688 |  Val. Acc: 55.16%\n",
            "\tTrain Loss: 0.687 | Train Acc: 55.47%\n",
            "\t Val. Loss: 0.687 |  Val. Acc: 55.16%\n",
            "\tTrain Loss: 0.687 | Train Acc: 55.48%\n",
            "\t Val. Loss: 0.688 |  Val. Acc: 55.16%\n",
            "\tTrain Loss: 0.687 | Train Acc: 55.49%\n",
            "\t Val. Loss: 0.687 |  Val. Acc: 55.16%\n",
            "\tTrain Loss: 0.686 | Train Acc: 55.48%\n",
            "\t Val. Loss: 0.687 |  Val. Acc: 55.16%\n",
            "\tTrain Loss: 0.685 | Train Acc: 55.48%\n",
            "\t Val. Loss: 0.686 |  Val. Acc: 55.12%\n",
            "\tTrain Loss: 0.681 | Train Acc: 55.93%\n",
            "\t Val. Loss: 0.685 |  Val. Acc: 55.09%\n",
            "\tTrain Loss: 0.678 | Train Acc: 57.05%\n",
            "\t Val. Loss: 0.684 |  Val. Acc: 55.30%\n",
            "\tTrain Loss: 0.673 | Train Acc: 57.99%\n",
            "\t Val. Loss: 0.684 |  Val. Acc: 54.38%\n",
            "\tTrain Loss: 0.671 | Train Acc: 58.88%\n",
            "\t Val. Loss: 0.684 |  Val. Acc: 55.94%\n",
            "\tTrain Loss: 0.667 | Train Acc: 59.44%\n",
            "\t Val. Loss: 0.685 |  Val. Acc: 55.39%\n",
            "\tTrain Loss: 0.664 | Train Acc: 60.22%\n",
            "\t Val. Loss: 0.685 |  Val. Acc: 56.38%\n",
            "\tTrain Loss: 0.661 | Train Acc: 60.45%\n",
            "\t Val. Loss: 0.685 |  Val. Acc: 56.42%\n",
            "\tTrain Loss: 0.656 | Train Acc: 61.14%\n",
            "\t Val. Loss: 0.687 |  Val. Acc: 55.78%\n",
            "\tTrain Loss: 0.652 | Train Acc: 61.78%\n",
            "\t Val. Loss: 0.689 |  Val. Acc: 55.87%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5fG5OLZTNYI",
        "outputId": "10037a51-807b-4b11-a23c-7f46ec9a4807"
      },
      "source": [
        "print(best_valid_accuracy)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5642289957579445\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}